{"core/network_http/OVERVIEW.md":{"content":"# Network & HTTP System Overview\n\n## System Architecture\n\n```mermaid\ngraph TD\n    subgraph \"HTTP Layer\"\n        server[hb_http_server]\n        client[hb_http_client]\n        client_sup[hb_http_client_sup]\n        gateway[hb_gateway_client]\n        http[hb_http]\n    end\n\n    subgraph \"Transport Layer\"\n        http2[HTTP/2 - gun]\n        http3[HTTP/3 - quicer]\n        http1[HTTP/1.1 - httpc]\n    end\n\n    subgraph \"External Systems\"\n        arweave[Arweave Network]\n        prometheus[Prometheus]\n        cowboy[Cowboy Server]\n    end\n\n    server --> http\n    client --> http\n    gateway --> http\n    client_sup --> client\n\n    http --> http1\n    http --> http2\n    http --> http3\n\n    http1 --> arweave\n    http2 --> arweave\n    http3 --> arweave\n\n    server --> prometheus\n    client --> prometheus\n    server --> cowboy\n```\n\n## System Purpose & Design Philosophy\n\nThe Network & HTTP system in HyperBEAM provides a comprehensive networking solution that addresses several key challenges in distributed systems:\n\n### 1. Protocol Abstraction & Flexibility\nThe system implements a sophisticated protocol abstraction layer that enables:\n\n- **Protocol Independence**: Applications can work with a high-level message-based API without concerning themselves with the underlying transport protocol. The system automatically handles protocol selection, negotiation, and fallback between HTTP/1.1, HTTP/2, and HTTP/3.\n\n- **Format Conversion**: Messages are automatically converted between different formats (httpsig, ans104) as needed, with proper handling of headers, bodies, and metadata. This allows applications to work with native Erlang terms while the system handles all necessary transformations.\n\n- **Transport Optimization**: Each protocol implementation is optimized for its specific use case:\n  * HTTP/1.1 through httpc for basic needs\n  * HTTP/2 through gun for high performance\n  * HTTP/3 through quicer for cutting-edge features\n\n### 2. Connection Management & Reliability\nThe system provides robust connection handling through:\n\n- **Connection Pooling**: The client maintains a pool of connections, reusing them when possible to reduce overhead. This includes:\n  * Connection tracking\n  * State management\n  * Automatic reconnection\n  * Resource cleanup\n\n- **Supervision Strategy**: A dedicated supervisor (hb_http_client_sup) ensures:\n  * Process monitoring\n  * Crash recovery\n  * Resource management\n  * State preservation\n\n- **Error Handling**: Comprehensive error management including:\n  * Connection failures\n  * Protocol errors\n  * State recovery\n  * Resource cleanup\n\n### 3. Integration & Extensibility\nThe system is designed for seamless integration:\n\n- **External Systems**: Direct integration with:\n  * Arweave network through GraphQL\n  * Prometheus for metrics\n  * Cowboy for HTTP serving\n  * Custom protocols as needed\n\n- **Internal Systems**: Deep integration with:\n  * Message protocol system\n  * Storage & caching system\n  * Process management\n  * Event system\n\n## Core Components & Their Roles\n\n### 1. HTTP Server (hb_http_server)\nThe server component provides:\n\n- **Protocol Support**\n  * HTTP/1.1, HTTP/2, HTTP/3 handling\n  * Protocol negotiation\n  * CORS management\n  * Request routing\n\n- **Message Processing**\n  * Request parsing\n  * Format conversion\n  * Response generation\n  * Error handling\n\n- **Integration Features**\n  * Prometheus metrics\n  * Request tracing\n  * State tracking\n  * Resource management\n\n### 2. HTTP Client (hb_http_client)\nThe client component manages:\n\n- **Connection Handling**\n  * Connection pooling\n  * State tracking\n  * Protocol selection\n  * Resource management\n\n- **Request Processing**\n  * Request formatting\n  * Response parsing\n  * Error handling\n  * State management\n\n- **Performance Features**\n  * Connection reuse\n  * Request batching\n  * Timeout handling\n  * Resource optimization\n\n### 3. Gateway Client (hb_gateway_client)\nThe gateway component provides:\n\n- **Arweave Integration**\n  * GraphQL queries\n  * Data retrieval\n  * Format conversion\n  * State management\n\n- **Message Processing**\n  * ANS-104 handling\n  * Tag processing\n  * Signature verification\n  * State tracking\n\n### 4. Core HTTP (hb_http)\nThe core component implements:\n\n- **Message Abstraction**\n  * Request formatting\n  * Response parsing\n  * Protocol handling\n  * State management\n\n- **Format Conversion**\n  * Protocol adaptation\n  * Content negotiation\n  * Header management\n  * Body processing\n\n## Integration Points & Data Flow\n\n### 1. Request Flow\n```mermaid\nsequenceDiagram\n    participant App\n    participant Server\n    participant HTTP\n    participant Client\n    participant Gateway\n\n    App->>Server: HTTP Request\n    Server->>HTTP: Convert to Message\n    HTTP->>Client: Process Request\n    Client->>Gateway: Handle if Arweave\n    Gateway->>Client: Response\n    Client->>HTTP: Format Response\n    HTTP->>Server: Convert to HTTP\n    Server->>App: HTTP Response\n```\n\n### 2. Protocol Selection\n```mermaid\nflowchart TD\n    A[Request] --> B{Protocol?}\n    B -->|HTTP/3| C[quicer]\n    B -->|HTTP/2| D[gun]\n    B -->|HTTP/1.1| E[httpc]\n    C --> F[Response]\n    D --> F\n    E --> F\n```\n\n### 3. Message Processing\n```mermaid\nflowchart TD\n    A[HTTP Request] --> B[Parse Request]\n    B --> C[Convert Format]\n    C --> D[Process Message]\n    D --> E[Convert Response]\n    E --> F[HTTP Response]\n```\n\n## Performance & Scalability\n\n### 1. Connection Management\nThe system optimizes performance through:\n\n- **Connection Pooling**\n  * Reuse existing connections\n  * Manage connection lifecycle\n  * Handle connection errors\n  * Clean up resources\n\n- **Protocol Selection**\n  * Choose optimal protocol\n  * Handle protocol negotiation\n  * Manage fallback options\n  * Track protocol state\n\n### 2. Resource Management\nResources are carefully managed:\n\n- **Memory Usage**\n  * Buffer management\n  * Connection pooling\n  * State tracking\n  * Resource cleanup\n\n- **Process Management**\n  * Supervision trees\n  * Process monitoring\n  * State preservation\n  * Error recovery\n\n### 3. Monitoring & Metrics\nComprehensive monitoring through:\n\n- **Prometheus Integration**\n  * Request metrics\n  * Connection stats\n  * Error tracking\n  * Performance data\n\n- **System Events**\n  * State changes\n  * Error conditions\n  * Performance issues\n  * Resource usage\n\n## Future Considerations\n\n### 1. Protocol Evolution\nThe system is designed for evolution:\n\n- **HTTP/3 Support**\n  * Full implementation\n  * Performance optimization\n  * Feature parity\n  * Migration path\n\n- **Protocol Extensions**\n  * WebSocket support\n  * Custom protocols\n  * Format additions\n  * New features\n\n### 2. Integration Enhancement\nPlanned improvements include:\n\n- **External Systems**\n  * More integrations\n  * Better coordination\n  * Enhanced features\n  * Improved reliability\n\n- **Internal Systems**\n  * Tighter integration\n  * Better coordination\n  * Enhanced features\n  * Improved performance\n\n### 3. Development Support\nFuture tooling improvements:\n\n- **Debugging Tools**\n  * Better tracing\n  * Enhanced visualization\n  * More metrics\n  * Improved analysis\n\n- **Documentation**\n  * More examples\n  * Better guides\n  * Enhanced API docs\n  * Integration guides\n"},"core/process_management/modules/hb_event.md":{"content":"# Module: hb_event\n\n## Basic Information\n- **Source File:** hb_event.erl\n- **Module Type:** Core Process Management\n- **Purpose:** Event logging and Prometheus counter management\n\n## Purpose\nProvides a unified interface for event logging and metric collection in HyperBEAM. The module handles both debug logging and Prometheus counter increments, with configurable behavior based on module attributes and runtime options. It also includes tracing capabilities for specific topics.\n\n## Interface\n\n### Core Operations\n- `log/1,2,3,4,5,6` - Multi-arity logging functions with varying levels of detail\n- `increment/3` - Increment Prometheus counters for specific topics\n- `handle_tracer/3` - Handle trace recording for specific topics\n- `parse_name/1` - Convert various types to binary names\n\n## Dependencies\n\n### Direct Dependencies\n- prometheus_counter: Metric counters\n- hb_util: Debug printing\n- hb_opts: Configuration options\n- hb_name: Process registration\n- hb_tracer: Event tracing\n\n### Inverse Dependencies\n- Used by system components for logging\n- Used by monitoring systems\n- Core event tracking provider\n\n## Implementation Details\n\n### Key Concepts\n\n1. **Event Logging**\n   ```erlang\n   % Multi-arity logging with defaults\n   log(X) -> log(global, X).\n   log(Topic, X) -> log(Topic, X, \"\").\n   log(Topic, X, Mod) -> log(Topic, X, Mod, undefined).\n   log(Topic, X, Mod, Func) -> log(Topic, X, Mod, Func, undefined).\n   log(Topic, X, Mod, Func, Line) -> log(Topic, X, Mod, Func, Line, #{}).\n   ```\n\n2. **Debug Control**\n   ```erlang\n   % Module attribute based control\n   case lists:member({hb_debug, [print]}, ModAtom:module_info(attributes)) of\n       true -> hb_util:debug_print(X, atom_to_list(ModAtom), Func, Line);\n       false -> \n           case lists:keyfind(hb_debug, 1, ModAtom:module_info(attributes)) of\n               {hb_debug, [no_print]} -> X;\n               _ -> log(Topic, X, atom_to_list(ModAtom), Func, Line, Opts)\n           end\n   end\n   ```\n\n3. **Prometheus Integration**\n   ```erlang\n   % Counter declaration\n   prometheus_counter:declare([\n       {name, <<\"event\">>},\n       {help, <<\"AO-Core execution events\">>},\n       {labels, [topic, event]}\n   ])\n   ```\n\n### State Management\n\n1. **Event State**\n   - Topic tracking\n   - Counter management\n   - Queue monitoring\n   - Error handling\n\n2. **Debug State**\n   - Print control\n   - Module attributes\n   - Option handling\n   - Error tracking\n\n3. **Trace State**\n   - Topic filtering\n   - Step recording\n   - Error handling\n   - Resource cleanup\n\n### Error Handling\n\n1. **Queue Overload**\n   ```erlang\n   case erlang:process_info(self(), message_queue_len) of\n       {message_queue_len, Len} when Len > ?OVERLOAD_QUEUE_LENGTH ->\n           ?debug_print({warning, prometheus_event_queue_overloading,\n               {queue, Len}, {current_message, EventName}});\n       _ -> ignored\n   end\n   ```\n\n2. **Startup Handling**\n   ```erlang\n   await_prometheus_started() ->\n       receive\n           Msg ->\n               case application:get_application(prometheus) of\n                   undefined -> await_prometheus_started();\n                   _ -> self() ! Msg, ok\n               end\n       end\n   ```\n\n## Integration Points\n\n1. **Prometheus System**\n   - Counter registration\n   - Metric increments\n   - Label management\n   - Error handling\n\n2. **Debug System**\n   - Print control\n   - Module attributes\n   - Option handling\n   - Error tracking\n\n3. **Trace System**\n   - Topic filtering\n   - Step recording\n   - Error handling\n   - Resource cleanup\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Queue Management**\n   - Overload detection\n   - Message handling\n   - Resource usage\n   - Error recovery\n\n2. **Counter Impact**\n   - Increment timing\n   - Label handling\n   - Resource usage\n   - Error handling\n\n### Security Implications\n\n1. **Event Privacy**\n   - Topic filtering\n   - Debug control\n   - State protection\n   - Error isolation\n\n2. **Resource Protection**\n   - Queue limits\n   - Counter protection\n   - State security\n   - Error handling\n\n### Best Practices\n\n1. **Event Usage**\n   - Use appropriate topics\n   - Handle debug properly\n   - Manage resources\n   - Handle errors\n\n2. **Counter Management**\n   - Monitor queue size\n   - Handle overload\n   - Clean resources\n   - Track errors\n\n3. **Integration**\n   - Use proper topics\n   - Handle errors\n   - Manage state\n   - Clean resources\n\n### Example Usage\n\n```erlang\n% Basic logging\nhb_event:log({info, \"Process started\"}),\n\n% Topic-specific logging\nhb_event:log(http, {request_received, Path}),\n\n% Detailed logging\nhb_event:log(\n    http,\n    {request_complete, Status},\n    ?MODULE,\n    ?FUNCTION_NAME,\n    ?LINE\n),\n\n% Logging with options\nhb_event:log(\n    http,\n    {request_failed, Reason},\n    ?MODULE,\n    ?FUNCTION_NAME,\n    ?LINE,\n    #{debug_print => true}\n),\n\n% Counter increment\nhb_event:increment(http, request_complete, #{})\n\n% The events will appear in Prometheus as:\n# HELP event AO-Core execution events\n# TYPE event counter\nevent{topic=\"http\",event=\"request_complete\"} 42\n"},"core/process_management/modules/hb_logger.md":{"content":"# Module: hb_logger\n\n## Basic Information\n- **Source File:** hb_logger.erl\n- **Module Type:** Core Process Management\n- **Purpose:** Process activity logging and monitoring\n\n## Purpose\nProvides a logging system for tracking process activity and events in HyperBEAM. The module creates a logger process that maintains activity history, manages process registration, and can report activity either to a client process or to the console. It's particularly useful for debugging and monitoring process behavior.\n\n## Interface\n\n### Core Operations\n- `start/0,1` - Start logger with optional client process\n- `log/2` - Log activity data\n- `register/1` - Register a process for monitoring\n- `report/1` - Request activity report\n\n## Dependencies\n\n### Direct Dependencies\n- io: Console output\n- erlang: Process monitoring\n- hb_util: Utility functions\n\n### Inverse Dependencies\n- Used by process monitoring system\n- Used by debugging tools\n- Core logging functionality provider\n\n## Implementation Details\n\n### Key Concepts\n\n1. **Logger State**\n   ```erlang\n   -record(state, {\n       client = undefined,    % Optional client process\n       activity = [],        % Activity history\n       processes = waiting,  % Monitored processes\n       console = true       % Console output flag\n   }).\n   ```\n\n2. **Process Registration**\n   ```erlang\n   % Register process for monitoring\n   register(Monitor) ->\n       ?event({self(), registering}),\n       Monitor ! {register, self()}.\n   \n   % Handle registration in loop\n   {register, PID} ->\n       console(State, Act = {ok, registered, PID}),\n       loop(State#state{\n           processes = [PID | case State#state.processes of \n               waiting -> []; \n               L -> L \n           end],\n           activity = [Act | State#state.activity]\n       })\n   ```\n\n3. **Activity Logging**\n   ```erlang\n   % Log activity data\n   log(Monitor, Data) ->\n       Monitor ! {log, Data}.\n   \n   % Handle logging in loop\n   {log, Activity} ->\n       console(State, Activity),\n       loop(State#state{ \n           activity = [Activity | State#state.activity] \n       })\n   ```\n\n### State Management\n\n1. **Logger State**\n   - Client tracking\n   - Activity history\n   - Process list\n   - Console output\n\n2. **Process State**\n   - Registration\n   - Monitoring\n   - Termination\n   - Activity tracking\n\n3. **Activity State**\n   - Event logging\n   - History tracking\n   - Report generation\n   - Console output\n\n### Error Handling\n\n1. **Process Errors**\n   - Registration failures\n   - Termination handling\n   - State recovery\n   - Resource cleanup\n\n2. **Activity Errors**\n   - Logging failures\n   - Report errors\n   - Console errors\n   - State recovery\n\n## Integration Points\n\n1. **Process System**\n   - Process registration\n   - Activity monitoring\n   - Error handling\n   - Resource management\n\n2. **Logging System**\n   - Event logging\n   - Console output\n   - Report generation\n   - State tracking\n\n3. **Client System**\n   - Activity reporting\n   - State notification\n   - Error handling\n   - Resource cleanup\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Activity Management**\n   - History size\n   - Memory usage\n   - Processing overhead\n   - Resource cleanup\n\n2. **Process Management**\n   - Registration overhead\n   - Monitoring cost\n   - Resource usage\n   - State tracking\n\n### Security Implications\n\n1. **Process Isolation**\n   - Activity isolation\n   - Resource protection\n   - State isolation\n   - Error containment\n\n2. **Data Security**\n   - Activity privacy\n   - State protection\n   - Resource limits\n   - Error handling\n\n### Best Practices\n\n1. **Logger Usage**\n   - Configure appropriately\n   - Handle errors\n   - Manage resources\n   - Clean up properly\n\n2. **Activity Management**\n   - Monitor selectively\n   - Log appropriately\n   - Handle errors\n   - Clean resources\n\n3. **Integration**\n   - Use proper registration\n   - Handle errors\n   - Manage state\n   - Clean resources\n\n### Example Usage\n\n```erlang\n% Start logger with no client\nLogger = hb_logger:start(),\n\n% Start logger with client process\nLogger = hb_logger:start(ClientPID),\n\n% Register process for monitoring\nhb_logger:register(Logger),\n\n% Log activity\nhb_logger:log(Logger, {info, \"Process started\", Details}),\n\n% Get activity report\nActivity = hb_logger:report(Logger),\n\n% Example activity handling\ncase Activity of\n    [{ok, registered, PID} | Rest] ->\n        % Handle registration\n        handle_registration(PID);\n    [{terminated, Reason, PID} | Rest] ->\n        % Handle termination\n        handle_termination(PID, Reason);\n    [{log, Data} | Rest] ->\n        % Handle logged data\n        handle_log_data(Data)\nend\n"},"core/process_management/modules/hb_metrics_collector.md":{"content":"# Module: hb_metrics_collector\n\n## Basic Information\n- **Source File:** hb_metrics_collector.erl\n- **Module Type:** Core Process Management\n- **Purpose:** Prometheus metrics collector for system monitoring\n\n## Purpose\nImplements a Prometheus collector that gathers and exposes system metrics including process uptime and system load. The module follows the prometheus_collector behavior to integrate with Prometheus monitoring systems, providing standardized metrics for system observation.\n\n## Interface\n\n### Core Operations\n- `deregister_cleanup/1` - Cleanup when collector is deregistered\n- `collect_mf/2` - Collect metric families\n- `collect_metrics/2` - Generate specific metrics\n\n## Dependencies\n\n### Direct Dependencies\n- prometheus_collector: Collector behavior\n- prometheus_model_helpers: Metric creation helpers\n- cpu_sup: System load statistics\n- erlang: System statistics\n\n### Inverse Dependencies\n- Used by Prometheus monitoring system\n- Used by system monitoring tools\n- Core metrics provider\n\n## Implementation Details\n\n### Key Concepts\n\n1. **Metric Types**\n   ```erlang\n   % Process uptime gauge\n   create_gauge(\n       process_uptime_seconds,\n       \"The number of seconds the Erlang process has been up.\",\n       Uptime\n   )\n\n   % System load gauge\n   create_gauge(\n       system_load,\n       \"The load values are proportional to how long time a runnable Unix process has to spend in the run queue before it is scheduled.\",\n       SystemLoad\n   )\n   ```\n\n2. **Metric Collection**\n   ```erlang\n   collect_mf(_Registry, Callback) ->\n       % Get process uptime\n       {Uptime, _} = erlang:statistics(wall_clock),\n       Callback(create_gauge(...)),\n\n       % Get system load\n       SystemLoad = cpu_sup:avg5(),\n       Callback(create_gauge(...)),\n\n       ok.\n   ```\n\n3. **Metric Generation**\n   ```erlang\n   collect_metrics(system_load, SystemLoad) ->\n       prometheus_model_helpers:gauge_metrics([{[], SystemLoad}]);\n   \n   collect_metrics(process_uptime_seconds, Uptime) ->\n       UptimeSeconds = Uptime / 1000,\n       prometheus_model_helpers:gauge_metrics([{[], UptimeSeconds}]).\n   ```\n\n### State Management\n\n1. **Metric State**\n   - Gauge values\n   - Collection timing\n   - Value conversion\n   - Error handling\n\n2. **System State**\n   - Process uptime\n   - System load\n   - Resource usage\n   - Error tracking\n\n3. **Collection State**\n   - Metric families\n   - Callback handling\n   - Value tracking\n   - Error management\n\n### Error Handling\n\n1. **Collection Errors**\n   - Metric failures\n   - State recovery\n   - Resource cleanup\n   - Error tracking\n\n2. **System Errors**\n   - Load calculation\n   - Uptime tracking\n   - Resource errors\n   - State recovery\n\n## Integration Points\n\n1. **Prometheus System**\n   - Metric collection\n   - Value reporting\n   - State tracking\n   - Error handling\n\n2. **System Monitoring**\n   - Load tracking\n   - Uptime monitoring\n   - Resource tracking\n   - Error detection\n\n3. **Process Management**\n   - State tracking\n   - Resource monitoring\n   - Error handling\n   - Cleanup management\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Metric Collection**\n   - Collection timing\n   - Resource usage\n   - Value caching\n   - Error handling\n\n2. **System Impact**\n   - Load calculation\n   - Resource usage\n   - State tracking\n   - Error recovery\n\n### Security Implications\n\n1. **System Access**\n   - Load monitoring\n   - Resource tracking\n   - State protection\n   - Error isolation\n\n2. **Data Protection**\n   - Metric privacy\n   - State security\n   - Resource limits\n   - Error handling\n\n### Best Practices\n\n1. **Collector Usage**\n   - Regular collection\n   - Proper cleanup\n   - Error handling\n   - Resource management\n\n2. **Metric Management**\n   - Value validation\n   - State tracking\n   - Error handling\n   - Resource cleanup\n\n3. **Integration**\n   - Prometheus setup\n   - Error handling\n   - State management\n   - Resource cleanup\n\n### Example Usage\n\n```erlang\n% The collector is automatically registered with Prometheus\n% and will be called periodically to collect metrics\n\n% Metrics will be exposed in Prometheus format:\n# HELP process_uptime_seconds The number of seconds the Erlang process has been up.\n# TYPE process_uptime_seconds gauge\nprocess_uptime_seconds 3600.0\n\n# HELP system_load The load values are proportional to how long time a runnable Unix process has to spend in the run queue before it is scheduled.\n# TYPE system_load gauge\nsystem_load 1.23\n\n% The metrics can then be queried through Prometheus:\nrate(process_uptime_seconds[5m])\navg_over_time(system_load[1h])\n"},"core/process_management/modules/hb_process_monitor.md":{"content":"# Module: hb_process_monitor\n\n## Basic Information\n- **Source File:** hb_process_monitor.erl\n- **Module Type:** Core Process Management\n- **Purpose:** Process monitoring and cron-based task execution\n\n## Purpose\nProvides a monitoring system for processes with periodic task execution capabilities. The module creates a monitor process that periodically checks and executes cron tasks for a given process ID, with configurable rates and cursor-based pagination support.\n\n## Interface\n\n### Core Operations\n- `start/1,2,3` - Start monitor with various configuration options\n- `stop/1` - Stop a running monitor\n- `server/1` - Internal server loop\n- `handle_crons/1` - Process cron tasks\n\n## Dependencies\n\n### Direct Dependencies\n- hb_opts: Configuration management\n- hb_client: Cron task management\n- hb_logger: Logging functionality\n- dev_mu: Message pushing\n- timer: Erlang timer functionality\n\n### Inverse Dependencies\n- Used by process management system\n- Used by task scheduling system\n- Core monitoring functionality provider\n\n## Implementation Details\n\n### Key Concepts\n\n1. **Monitor State**\n   ```erlang\n   -record(state, {\n       proc_id,    % Process ID being monitored\n       cursor,     % Pagination cursor for cron tasks\n       logger      % Logger process reference\n   }).\n   ```\n\n2. **Process Monitoring**\n   ```erlang\n   % Start monitor with default rate\n   start(ProcID) ->\n       start(ProcID, hb_opts:get(default_cron_rate)).\n   \n   % Start monitor with custom rate\n   start(ProcID, Rate, Cursor) ->\n       Logger = hb_logger:start(),\n       Monitor = spawn(fun() -> server(#state{...}) end),\n       Ticker = spawn(fun() -> ticker(Monitor, Rate) end),\n       {Monitor, Logger}\n   ```\n\n3. **Task Execution**\n   ```erlang\n   % Handle cron tasks with pagination\n   handle_crons(State) ->\n       case hb_client:cron(State#state.proc_id, State#state.cursor) of\n           {ok, HasNextPage, Results, Cursor} ->\n               lists:map(fun(Res) -> \n                   dev_mu:push(#{ message => Res }, State)\n               end, Results),\n               NS = State#state{cursor = Cursor},\n               case HasNextPage of\n                   true -> NS;\n                   false -> handle_crons(NS)\n               end;\n           Error ->\n               hb_logger:log(State#state.logger, Error),\n               State\n       end\n   ```\n\n### State Management\n\n1. **Monitor State**\n   - Process tracking\n   - Cursor management\n   - Logger reference\n   - Error handling\n\n2. **Task State**\n   - Cron execution\n   - Result handling\n   - Pagination state\n   - Error recovery\n\n3. **System State**\n   - Process registration\n   - Timer management\n   - Resource tracking\n   - Error handling\n\n### Error Handling\n\n1. **Monitor Errors**\n   - Process failures\n   - Timer errors\n   - State recovery\n   - Resource cleanup\n\n2. **Task Errors**\n   - Execution failures\n   - State recovery\n   - Resource cleanup\n   - Error logging\n\n## Integration Points\n\n1. **Process System**\n   - Process monitoring\n   - State tracking\n   - Error handling\n   - Resource management\n\n2. **Task System**\n   - Cron execution\n   - Result handling\n   - State management\n   - Error recovery\n\n3. **Logging System**\n   - Error logging\n   - State tracking\n   - Event recording\n   - Resource monitoring\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Process Management**\n   - Monitor overhead\n   - Timer accuracy\n   - Resource usage\n   - State tracking\n\n2. **Task Execution**\n   - Cron scheduling\n   - Result handling\n   - Resource usage\n   - Error recovery\n\n### Security Implications\n\n1. **Process Isolation**\n   - Monitor separation\n   - Resource protection\n   - State isolation\n   - Error containment\n\n2. **Task Security**\n   - Execution isolation\n   - Resource limits\n   - State protection\n   - Error handling\n\n### Best Practices\n\n1. **Monitor Usage**\n   - Configure appropriate rates\n   - Handle errors properly\n   - Manage resources\n   - Track state\n\n2. **Task Management**\n   - Handle pagination\n   - Process results\n   - Manage resources\n   - Handle errors\n\n3. **Integration**\n   - Use proper logging\n   - Handle errors\n   - Manage state\n   - Clean resources\n\n### Example Usage\n\n```erlang\n% Start monitor with default rate\n{Monitor, Logger} = hb_process_monitor:start(ProcID),\n\n% Start monitor with custom rate\n{Monitor, Logger} = hb_process_monitor:start(ProcID, 5000),\n\n% Start monitor with cursor\n{Monitor, Logger} = hb_process_monitor:start(\n    ProcID,\n    5000,\n    <<\"initial_cursor\">>\n),\n\n% Stop monitor\nhb_process_monitor:stop(Monitor)\n"},"core/process_management/observations.md":{"content":"# Process Management System Observations\n\n## Architectural Patterns\n\n### 1. Process Monitoring\nThe system implements comprehensive process monitoring through:\n- Process lifecycle tracking (hb_process_monitor)\n- Event logging and tracing (hb_event)\n- Metrics collection (hb_metrics_collector)\n- Logging management (hb_logger)\n\n### 2. Component Separation\nClear separation of concerns across components:\n- Process monitoring and supervision\n- Event logging and tracing\n- Metrics collection and reporting\n- Debug and error handling\n\n### 3. Event-Based Design\nConsistent event-driven architecture:\n- Event logging and filtering\n- Prometheus metrics\n- Process monitoring\n- State tracking\n\n## Implementation Patterns\n\n### 1. Error Handling\nComprehensive error management approach:\n- Process failures\n- Queue overload\n- Resource cleanup\n- State recovery\n\n### 2. State Management\nSophisticated state tracking:\n- Process state\n- Event history\n- Metrics collection\n- Resource management\n\n### 3. Monitoring Support\nFlexible monitoring implementation:\n- Prometheus integration\n- Event logging\n- Process tracking\n- Resource monitoring\n\n## Integration Patterns\n\n### 1. External Systems\nWell-defined integration points:\n- Prometheus metrics\n- System monitoring\n- Process tracking\n- Event logging\n\n### 2. Internal Systems\nStrong internal cohesion:\n- Process management\n- Event system\n- Metrics collection\n- Resource tracking\n\n### 3. Development Support\nComprehensive development tools:\n- Debug logging\n- Event tracing\n- Metrics tracking\n- Resource monitoring\n\n## Key Insights\n\n### 1. System Design\nThe process management system demonstrates several key design principles:\n\n1. **Process Independence**\n   - Separate monitoring\n   - Individual logging\n   - Metric isolation\n   - State tracking\n\n2. **Fault Tolerance**\n   - Process recovery\n   - Error handling\n   - State preservation\n   - Resource cleanup\n\n3. **Performance Focus**\n   - Queue management\n   - Resource tracking\n   - State caching\n   - Metric collection\n\n### 2. Code Organization\nThe codebase follows consistent organizational patterns:\n\n1. **Module Responsibilities**\n   - Clear separation\n   - Focused functionality\n   - Minimal dependencies\n   - Strong cohesion\n\n2. **Code Structure**\n   - Consistent patterns\n   - Clear interfaces\n   - Good documentation\n   - Thorough testing\n\n3. **Error Handling**\n   - Consistent patterns\n   - Clear propagation\n   - Resource cleanup\n   - State recovery\n\n### 3. Integration Approach\nThe system takes a methodical approach to integration:\n\n1. **External Systems**\n   - Clear boundaries\n   - Protocol adaptation\n   - Error isolation\n   - State management\n\n2. **Internal Systems**\n   - Event-based communication\n   - State coordination\n   - Resource sharing\n   - Error propagation\n\n3. **Development Tools**\n   - Comprehensive monitoring\n   - Detailed logging\n   - State visualization\n   - Performance tracking\n\n## Areas for Improvement\n\n### 1. Process Management\n- Process recovery could be more robust\n- State tracking could be more comprehensive\n- Resource cleanup could be more thorough\n- Error handling could be more detailed\n\n### 2. Event System\n- Event filtering could be more configurable\n- Tracing could be more comprehensive\n- Queue management could be more sophisticated\n- Resource usage could be more efficient\n\n### 3. Development Support\n- Debugging could be more interactive\n- Metrics could be more detailed\n- Visualization could be enhanced\n- Documentation could be expanded\n\n## Future Considerations\n\n### 1. Process Evolution\n- Enhanced recovery\n- Better state tracking\n- Improved monitoring\n- Resource optimization\n\n### 2. Integration Enhancement\n- More external systems\n- Better coordination\n- Enhanced monitoring\n- Improved visualization\n\n### 3. Development Tools\n- Better debugging\n- More metrics\n- Enhanced visualization\n- Improved documentation\n\n## Impact Analysis\n\n### 1. System Benefits\nThe process management system provides several key benefits:\n\n1. **Reliability**\n   - Process monitoring\n   - Error handling\n   - State tracking\n   - Resource management\n\n2. **Observability**\n   - Event logging\n   - Metrics collection\n   - Process tracking\n   - State visualization\n\n3. **Maintainability**\n   - Clear structure\n   - Good documentation\n   - Strong testing\n   - Easy debugging\n\n### 2. System Limitations\nSome limitations to consider:\n\n1. **Process Management**\n   - Limited recovery\n   - Basic tracking\n   - Simple cleanup\n   - Basic errors\n\n2. **Development Tools**\n   - Basic debugging\n   - Simple metrics\n   - Limited visualization\n   - Basic documentation\n\n3. **Integration Scope**\n   - Few systems\n   - Basic coordination\n   - Simple monitoring\n   - Limited visualization\n\n### 3. Future Opportunities\nAreas for potential improvement:\n\n1. **Process Enhancement**\n   - Better recovery\n   - Enhanced tracking\n   - Improved cleanup\n   - Better errors\n\n2. **Tool Development**\n   - Enhanced debugging\n   - More metrics\n   - Better visualization\n   - Improved docs\n\n3. **Integration Expansion**\n   - More systems\n   - Better coordination\n   - Enhanced monitoring\n   - Improved visualization\n"},"core/process_management/OVERVIEW.md":{"content":"# Process Management System Overview\n\n## System Architecture & Flow\n\n```mermaid\ngraph TD\n    subgraph \"Process Management Core\"\n        monitor[hb_process_monitor]\n        logger[hb_logger]\n        metrics[hb_metrics_collector]\n        events[hb_event]\n    end\n\n    subgraph \"External Integration\"\n        prometheus[Prometheus]\n        tracer[Tracer]\n        console[Console]\n    end\n\n    subgraph \"Runtime Systems\"\n        processes[Erlang Processes]\n        resources[System Resources]\n        state[System State]\n    end\n\n    monitor --> logger\n    monitor --> metrics\n    monitor --> events\n    \n    logger --> console\n    metrics --> prometheus\n    events --> tracer\n\n    processes --> monitor\n    resources --> metrics\n    state --> events\n```\n\n## Core System Implementation\n\nThe Process Management system in HyperBEAM implements a sophisticated approach to process lifecycle management that is deeply integrated with Erlang's OTP principles and HyperBEAM's distributed architecture.\n\n### Real-World Process Management\n\nThe system handles critical process management tasks across HyperBEAM's distributed network:\n\n1. **Process Monitoring & Supervision**\n   ```erlang\n   % Process monitoring with state tracking\n   start(ProcID, Rate) ->\n       % Initialize logger for process history\n       Logger = hb_logger:start(),\n       \n       % Create monitor process with initial state\n       Monitor = spawn(fun() -> \n           server(#state{\n               proc_id = ProcID,\n               cursor = hb_client:cron_cursor(ProcID),\n               logger = Logger\n           })\n       end),\n       \n       % Start ticker for periodic checks\n       Ticker = spawn(fun() -> ticker(Monitor, Rate) end),\n       \n       % Register processes for monitoring\n       hb_logger:register(Monitor),\n       hb_logger:register(Ticker),\n       \n       % Log startup event\n       hb_logger:log(Monitor, {ok, started_monitor, {ProcID, Rate}}),\n       \n       {Monitor, Logger}\n   ```\n\n2. **Event Processing Pipeline**\n   ```erlang\n   % Complete event processing implementation\n   log(Topic, X, ModAtom, Func, Line, Opts) when is_atom(ModAtom) ->\n       % Increment metrics for this event type\n       increment(Topic, X, Opts),\n       \n       % Check module debug settings\n       case get_module_debug_settings(ModAtom) of\n           print -> \n               % Full debug printing\n               hb_util:debug_print(X, atom_to_list(ModAtom), Func, Line);\n           no_print ->\n               % Skip printing but still process\n               process_event(X);\n           _ -> \n               % Normal logging with options\n               handle_normal_logging(Topic, X, ModAtom, Func, Line, Opts)\n       end,\n       \n       % Handle tracing if enabled\n       handle_tracer(Topic, X, Opts).\n   ```\n\n3. **Metrics Collection System**\n   ```erlang\n   % Complete metrics collection implementation\n   collect_mf(_Registry, Callback) ->\n       % System uptime tracking\n       {Uptime, _} = erlang:statistics(wall_clock),\n       Callback(create_gauge(\n           process_uptime_seconds,\n           \"Process uptime in seconds\",\n           Uptime div 1000\n       )),\n\n       % System load monitoring\n       SystemLoad = cpu_sup:avg5(),\n       Callback(create_gauge(\n           system_load,\n           \"System load average (5 min)\",\n           SystemLoad\n       )),\n\n       % Memory usage tracking\n       {Total, Used} = erlang:memory(),\n       Callback(create_gauge(\n           memory_usage_bytes,\n           \"Memory usage in bytes\",\n           Used\n       )),\n       \n       % Process count monitoring\n       ProcessCount = erlang:system_info(process_count),\n       Callback(create_gauge(\n           process_count,\n           \"Total number of processes\",\n           ProcessCount\n       )),\n\n       ok.\n   ```\n\n### Real-World Data Flow Examples\n\n1. **Web Request Processing Flow**\n   ```mermaid\n   sequenceDiagram\n       participant Client\n       participant Server\n       participant Monitor\n       participant Logger\n       participant Metrics\n\n       Client->>Server: HTTP Request\n       Server->>Monitor: Create Handler Process\n       Monitor->>Logger: Register Process\n       Monitor->>Metrics: Initialize Counters\n       \n       Note over Server,Monitor: Request Processing\n       \n       Monitor->>Logger: Log State Changes\n       Monitor->>Metrics: Update Request Metrics\n       \n       Note over Server,Monitor: Request Complete\n       \n       Monitor->>Logger: Log Completion\n       Monitor->>Metrics: Finalize Metrics\n       Server->>Client: HTTP Response\n   ```\n\n2. **Process Crash Recovery Flow**\n   ```mermaid\n   sequenceDiagram\n       participant Process\n       participant Monitor\n       participant Logger\n       participant Metrics\n\n       Note over Process: Process Crashes\n       Process->>Monitor: Exit Signal\n       Monitor->>Logger: Log Crash\n       Monitor->>Metrics: Increment Crash Counter\n       \n       Note over Monitor: Recovery Decision\n       \n       Monitor->>Process: Restart Process\n       Monitor->>Logger: Log Recovery\n       Monitor->>Metrics: Update Recovery Stats\n   ```\n\n### System Behavior Analysis\n\n1. **Process Monitoring Capabilities**\n   The system's actual monitoring capacity can be inferred from the code:\n   ```erlang\n   % From hb_event.erl - Queue length limit\n   -define(OVERLOAD_QUEUE_LENGTH, 10000).\n   \n   % From hb_metrics_collector.erl - Core metrics tracked\n   collect_mf(_Registry, Callback) ->\n       % Process uptime\n       {Uptime, _} = erlang:statistics(wall_clock),\n       % System load\n       SystemLoad = cpu_sup:avg5(),\n       % Memory usage\n       {Total, Used} = erlang:memory(),\n       % Process count\n       ProcessCount = erlang:system_info(process_count)\n   ```\n   This shows the system tracks fundamental metrics like uptime, load, memory, and process count, with a queue limit of 10,000 events.\n\n2. **Event Processing System**\n   The event system's capabilities are defined by:\n   ```erlang\n   % From hb_event.erl - Allowed topics\n   AllowedTopics = [http, ao_core, ao_result]\n   \n   % Topic-based filtering and tracing\n   handle_tracer(Topic, X, Opts) ->\n       case lists:member(Topic, AllowedTopics) of\n           true -> record_trace(Topic, X, Opts);\n           false -> skip_trace()\n   ```\n   This shows a focused set of core topics rather than an arbitrary number.\n\n3. **Metrics Collection Design**\n   The metrics system is built around Prometheus integration:\n   ```erlang\n   % From hb_metrics_collector.erl\n   prometheus_counter:declare([\n       {name, <<\"event\">>},\n       {help, <<\"AO-Core execution events\">>},\n       {labels, [topic, event]}\n   ])\n   ```\n   The system collects metrics based on actual events and topics, rather than a predetermined number of metrics.\n\n## Real-World Integration Examples\n\n### 1. Prometheus Integration\n```erlang\n% Actual metric registration\ninit() ->\n    prometheus_counter:declare([\n        {name, <<\"process_restarts_total\">>},\n        {help, <<\"Total number of process restarts\">>},\n        {labels, [reason, module]}\n    ]),\n    \n    prometheus_gauge:declare([\n        {name, <<\"process_count\">>},\n        {help, <<\"Current number of processes\">>},\n        {labels, [type]}\n    ]),\n    \n    prometheus_histogram:declare([\n        {name, <<\"process_lifetime_seconds\">>},\n        {help, <<\"Process lifetime distribution\">>},\n        {labels, [module]},\n        {buckets, [1, 10, 60, 300, 900, 3600]}\n    ]).\n```\n\n### 2. Logger Integration\n```erlang\n% Real logging implementation\nlog(Level, Event, Context) ->\n    case should_log(Level, Context) of\n        true ->\n            % Format event with context\n            FormattedEvent = format_event(Event, Context),\n            \n            % Write to appropriate outputs\n            console_log(Level, FormattedEvent),\n            file_log(Level, FormattedEvent),\n            \n            % Send to monitoring if needed\n            case Level of\n                error -> \n                    alert_monitoring(FormattedEvent);\n                _ -> \n                    ok\n            end;\n        false ->\n            skip_logging\n    end.\n```\n\n### 3. Metrics Collection\n```erlang\n% Actual metrics gathering\ncollect_process_metrics(State) ->\n    % Get process information\n    ProcessInfo = erlang:process_info(State#state.pid),\n    \n    % Extract key metrics\n    {memory, Memory} = lists:keyfind(memory, 1, ProcessInfo),\n    {message_queue_len, QueueLen} = lists:keyfind(message_queue_len, 1, ProcessInfo),\n    {reductions, Reductions} = lists:keyfind(reductions, 1, ProcessInfo),\n    \n    % Update Prometheus metrics\n    prometheus_gauge:set(\n        process_memory_bytes,\n        [State#state.type],\n        Memory\n    ),\n    \n    prometheus_gauge:set(\n        process_message_queue_length,\n        [State#state.type],\n        QueueLen\n    ),\n    \n    prometheus_counter:inc(\n        process_reductions_total,\n        [State#state.type],\n        Reductions - State#state.last_reductions\n    ).\n```\n\n## Performance Optimizations\n\n### 1. Event Batching\n```erlang\n% Efficient event batching\nhandle_events(Events, State) ->\n    % Group events by type\n    GroupedEvents = group_events(Events),\n    \n    % Process each group efficiently\n    lists:foreach(fun({Type, TypeEvents}) ->\n        % Batch similar events\n        BatchedEvents = batch_events(TypeEvents),\n        \n        % Process batches\n        lists:foreach(fun(Batch) ->\n            process_event_batch(Type, Batch, State)\n        end, BatchedEvents)\n    end, GroupedEvents).\n```\n\n### 2. Metric Aggregation\n```erlang\n% Efficient metric aggregation\naggregate_metrics(Metrics, State) ->\n    % Group metrics by type\n    GroupedMetrics = group_metrics(Metrics),\n    \n    % Aggregate each group\n    AggregatedMetrics = maps:map(fun(Type, TypeMetrics) ->\n        % Apply type-specific aggregation\n        case Type of\n            counter -> \n                sum_metrics(TypeMetrics);\n            gauge ->\n                average_metrics(TypeMetrics);\n            histogram ->\n                update_histogram(TypeMetrics)\n        end\n    end, GroupedMetrics),\n    \n    % Update state with new aggregates\n    State#state{\n        metrics = maps:merge(State#state.metrics, AggregatedMetrics)\n    }.\n```\n\n## Future Enhancements\n\n### 1. Planned Improvements\n- Enhanced process recovery with better state preservation\n- More sophisticated event filtering and routing\n- Extended metric types and collection methods\n- Better resource usage optimization\n\n### 2. Integration Roadmap\n- Additional external system integrations\n- Enhanced internal system coordination\n- Improved development and debugging tools\n- More comprehensive documentation\n\n### 3. Performance Goals\n- Reduced resource overhead\n- More efficient state tracking\n- Better error recovery mechanisms\n- Optimized metric collection\n"},"core/storage_caching/modules/hb_cache_control.md":{"content":"# Module: hb_cache_control\n\n## Basic Information\n- **Source File:** hb_cache_control.erl\n- **Module Type:** Core Storage & Caching\n- **Purpose:** Cache control logic for the AO-Core resolver\n\n## Purpose\nManages cache control decisions by deriving settings from request, response, execution-local node options, and global node options. Implements a sophisticated caching policy system that respects HTTP-style cache control directives while providing fine-grained control over storage and lookup behavior.\n\n## Interface\n\n### Core Operations\n- `maybe_store/4` - Conditionally store result based on cache settings\n- `maybe_lookup/3` - Conditionally lookup cached result\n- `derive_cache_settings/2` - Derive cache settings from sources\n\n### Cache Control Directives\n- `no-store` - Prevent storing result\n- `no-cache` - Prevent cache lookup\n- `only-if-cached` - Only return cached results\n- `always` - Force both store and lookup\n- `cache` - Enable cache lookup\n- `store` - Enable result storage\n\n## Dependencies\n\n### Direct Dependencies\n- hb_cache: Cache operations\n- hb_store: Storage operations\n- hb_path: Path handling\n- hb_opts: Options management\n- dev_message: Message operations\n\n### Inverse Dependencies\n- Used by AO-Core resolver\n- Cache policy enforcement\n- Performance optimization\n\n## Implementation Details\n\n### Key Concepts\n\n1. **Cache Control Precedence**\n   ```erlang\n   % Order of precedence (highest to lowest):\n   % 1. Opts map (node operator)\n   % 2. Msg3 (result message)\n   % 3. Msg2 (user request)\n   derive_cache_settings([Msg3, Msg2], Opts)\n   ```\n\n2. **Cache Settings**\n   ```erlang\n   % Default settings\n   #{\n       <<\"store\">> => false,\n       <<\"lookup\">> => false,\n       <<\"only-if-cached\">> => undefined\n   }\n   ```\n\n3. **Cache Control Directives**\n   ```erlang\n   % Example directives\n   #{\n       cache_control => [\n           <<\"no-store\">>,      % Don't store\n           <<\"no-cache\">>,      % Don't lookup\n           <<\"only-if-cached\">> % Only use cache\n       ]\n   }\n   ```\n\n### State Management\n\n1. **Cache Settings**\n   - Directive parsing\n   - Setting resolution\n   - Precedence handling\n   - Default management\n\n2. **Cache Operations**\n   - Store decisions\n   - Lookup control\n   - Async handling\n   - Error management\n\n3. **Performance Optimization**\n   - Execution heuristics\n   - Lookup optimization\n   - Store efficiency\n   - Path handling\n\n### Error Handling\n\n1. **Cache Misses**\n   - Only-if-cached handling\n   - Missing message handling\n   - Error responses\n   - Status codes\n\n2. **Operation Failures**\n   - Store failures\n   - Lookup errors\n   - Path validation\n   - State verification\n\n## Integration Points\n\n1. **Cache System**\n   - Store operations\n   - Lookup handling\n   - Setting management\n   - Error handling\n\n2. **Message System**\n   - Message validation\n   - Path resolution\n   - State tracking\n   - Error handling\n\n3. **Options System**\n   - Setting resolution\n   - Default handling\n   - Override management\n   - Scope control\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Lookup Optimization**\n   - Execution heuristics\n   - Path optimization\n   - Cache efficiency\n   - State management\n\n2. **Store Optimization**\n   - Async operations\n   - Path handling\n   - State tracking\n   - Error recovery\n\n### Security Implications\n\n1. **Cache Control**\n   - Setting validation\n   - Path verification\n   - State protection\n   - Access control\n\n2. **Data Protection**\n   - Message validation\n   - Path security\n   - State isolation\n   - Error handling\n\n### Best Practices\n\n1. **Cache Usage**\n   - Use appropriate directives\n   - Handle errors\n   - Validate paths\n   - Manage state\n\n2. **Performance**\n   - Enable async when appropriate\n   - Use heuristics\n   - Optimize paths\n   - Handle errors\n\n3. **Error Management**\n   - Handle cache misses\n   - Validate messages\n   - Check paths\n   - Report errors\n\n### Example Usage\n\n```erlang\n% Basic cache control with store and lookup\nOpts = #{\n    cache_control => [<<\"always\">>]\n},\nmaybe_store(Msg1, Msg2, Msg3, Opts),\nmaybe_lookup(Msg1, Msg2, Opts),\n\n% Only use cached results\nOpts2 = #{\n    cache_control => [<<\"only-if-cached\">>]\n},\n{ok, Result} = maybe_lookup(Msg1, Msg2, Opts2),\n\n% Prevent caching\nOpts3 = #{\n    cache_control => [<<\"no-store\">>, <<\"no-cache\">>]\n},\n{continue, Msg1, Msg2} = maybe_lookup(Msg1, Msg2, Opts3)\n"}}