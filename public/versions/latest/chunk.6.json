{"core/storage_caching/OVERVIEW.md":{"content":"# Storage & Caching System Overview\n\n## Architecture Overview\n\n```mermaid\ngraph TD\n    subgraph \"Storage Layer\"\n        hb_store[hb_store]\n        fs[hb_store_fs]\n        rocks[hb_store_rocksdb]\n        gateway[hb_store_gateway]\n        remote[hb_store_remote_node]\n        \n        hb_store --> fs\n        hb_store --> rocks\n        hb_store --> gateway\n        hb_store --> remote\n    end\n\n    subgraph \"Cache Layer\"\n        cache[hb_cache]\n        control[hb_cache_control]\n        render[hb_cache_render]\n        persistent[hb_persistent]\n        \n        cache --> control\n        cache --> render\n        cache --> persistent\n    end\n\n    subgraph \"External Systems\"\n        fs_system[File System]\n        rocksdb[RocksDB]\n        arweave[Arweave Network]\n        remote_nodes[Remote Nodes]\n        \n        fs --> fs_system\n        rocks --> rocksdb\n        gateway --> arweave\n        remote --> remote_nodes\n    end\n\n    cache --> hb_store\n```\n\n## System Purpose & Design Philosophy\n\nThe Storage & Caching system in HyperBEAM represents a sophisticated approach to data persistence and caching that addresses several key challenges in distributed systems:\n\n### 1. Flexible Storage Architecture\nThe system is built around a pluggable storage architecture that allows different storage backends to be used interchangeably. This is achieved through the hb_store behavior, which defines a common interface that all storage implementations must follow. This design enables:\n\n- **Storage Flexibility**: Applications can choose the most appropriate storage backend for their needs, whether that's local filesystem storage for development, RocksDB for high-performance requirements, or remote storage for distributed scenarios.\n\n- **Transparent Operation**: The common interface means that application code doesn't need to know which storage backend is being used. The same code works regardless of whether data is stored locally or remotely.\n\n- **Distributed Capabilities**: Through the gateway and remote node implementations, the system can seamlessly handle distributed storage scenarios, including integration with Arweave for permanent storage.\n\n### 2. Intelligent Caching System\nThe caching system is designed with performance and resource efficiency in mind, implementing sophisticated strategies for data management:\n\n- **Multi-layer Caching**: The system implements a three-layer approach to caching:\n  1. Raw binary data storage with content-based addressing for deduplication\n  2. Hashpath-based graph structure for efficient navigation and relationship tracking\n  3. Message-level caching with both committed and uncommitted states\n\n- **Policy-based Control**: Through hb_cache_control, the system provides HTTP-style cache control directives that allow fine-grained control over caching behavior:\n  * Cache invalidation strategies\n  * Storage policies\n  * Lookup behaviors\n  * Resource management\n\n- **Performance Optimization**: The system includes several performance optimizations:\n  * Content deduplication to minimize storage usage\n  * Path optimization for efficient access\n  * Process-based caching for frequently accessed data\n  * Asynchronous operations where appropriate\n\n### 3. Development and Debugging Support\nThe system includes comprehensive tools for development and debugging:\n\n- **Visualization Tools**: Through hb_cache_render, developers can:\n  * Generate visual representations of cache structures\n  * Analyze relationships between cached items\n  * Debug cache state and behavior\n  * Monitor system performance\n\n- **Debugging Capabilities**: The system provides extensive debugging support:\n  * Detailed logging of cache operations\n  * State inspection tools\n  * Performance monitoring\n  * Error tracking and analysis\n\n## Core Components & Their Interactions\n\n### 1. Storage Abstraction Layer (hb_store)\nThe hb_store module serves as the foundational abstraction layer for all storage operations in HyperBEAM. It provides:\n\n- **Common Interface**: A behavior-based interface that all storage backends must implement, ensuring consistent operation across different storage types. This includes operations for:\n  * Reading and writing data\n  * Creating and managing links between data\n  * Handling paths and directories\n  * Managing data types and metadata\n\n- **Path Resolution System**: A sophisticated path resolution mechanism that:\n  * Handles both simple and complex paths\n  * Resolves symbolic links and references\n  * Manages path normalization\n  * Provides consistent path handling across backends\n\n- **Operation Coordination**: Coordinates storage operations across multiple backends:\n  * Implements chain of responsibility pattern for store selection\n  * Handles fallback between stores\n  * Manages operation priorities\n  * Coordinates distributed operations\n\n- **Error Management**: Comprehensive error handling system that:\n  * Provides consistent error reporting\n  * Handles backend-specific errors\n  * Manages recovery procedures\n  * Ensures data consistency\n\n### 2. Storage Implementation Layer\nThe system provides multiple storage backends, each optimized for specific use cases:\n\n- **Filesystem Backend (hb_store_fs)**\n  * Uses local filesystem for storage, providing:\n    - Direct file access for maximum performance\n    - Native filesystem operations\n    - Symbolic link support\n    - Directory-based organization\n  * Implements path management through:\n    - Directory hierarchy\n    - File-based storage\n    - Link resolution\n    - Path normalization\n\n- **RocksDB Backend (hb_store_rocksdb)**\n  * High-performance key-value store offering:\n    - Optimized binary storage\n    - Fast key-value operations\n    - Efficient data compression\n    - Transaction support\n  * Enhanced with:\n    - Process-based wrapper\n    - Type annotation system\n    - Custom serialization\n    - Performance optimizations\n\n- **Gateway Backend (hb_store_gateway)**\n  * Provides Arweave network integration:\n    - Direct Arweave access\n    - GraphQL query support\n    - Transaction management\n    - Network optimization\n  * Features:\n    - Local caching system\n    - Request batching\n    - Response caching\n    - Error recovery\n\n- **Remote Node Backend (hb_store_remote_node)**\n  * Enables node-to-node communication:\n    - HTTP-based protocol\n    - Message authentication\n    - State synchronization\n    - Error handling\n  * Implements:\n    - Request signing\n    - Response validation\n    - State management\n    - Connection pooling\n\n### 3. Cache Management System\nA multi-layered caching system designed for performance and reliability:\n\n- **Core Cache (hb_cache)**\n  * Implements fundamental caching operations:\n    - Content-addressed storage\n    - Data deduplication\n    - Path-based access\n    - State management\n  * Provides:\n    - Format conversion\n    - Type handling\n    - Link management\n    - Cache invalidation\n\n- **Cache Control (hb_cache_control)**\n  * Manages caching policies through:\n    - HTTP-style directives\n    - Custom control options\n    - Performance settings\n    - Resource limits\n  * Features:\n    - Policy enforcement\n    - Setting resolution\n    - Cache optimization\n    - Resource management\n\n- **Cache Visualization (hb_cache_render)**\n  * Provides debugging and analysis tools:\n    - Graph visualization\n    - Structure analysis\n    - State inspection\n    - Performance monitoring\n  * Supports:\n    - DOT format generation\n    - SVG rendering\n    - Interactive debugging\n    - State exploration\n\n- **Persistent Cache (hb_persistent)**\n  * Manages long-lived cache processes:\n    - Process-based caching\n    - State persistence\n    - Message deduplication\n    - Resource coordination\n  * Implements:\n    - Worker management\n    - State synchronization\n    - Error recovery\n    - Resource cleanup\n\n## Key Features & Capabilities\n\n### 1. Advanced Storage Features\nThe storage system provides a rich set of features for data management:\n\n- **Backend Flexibility**\n  * Multiple storage implementations:\n    - Local filesystem for development\n    - RocksDB for high performance\n    - Gateway for Arweave integration\n    - Remote nodes for distribution\n  * Seamless backend switching\n  * Fallback mechanisms\n  * Mixed backend support\n\n- **Path Management**\n  * Sophisticated path abstraction:\n    - Hierarchical organization\n    - Link resolution\n    - Path normalization\n    - Type-aware paths\n  * Group management:\n    - Directory structures\n    - Namespace isolation\n    - Group permissions\n    - Hierarchical access\n\n- **Data Integrity**\n  * Comprehensive error handling:\n    - Operation validation\n    - State consistency\n    - Recovery procedures\n    - Error propagation\n  * State persistence:\n    - Reliable storage\n    - State recovery\n    - Transaction support\n    - Consistency guarantees\n\n### 2. Intelligent Cache Features\nThe caching system implements sophisticated features for performance:\n\n- **Policy Management**\n  * HTTP-style cache control:\n    - Cache directives\n    - Invalidation rules\n    - Storage policies\n    - Lookup behaviors\n  * Performance settings:\n    - Caching strategies\n    - Resource limits\n    - Timeout controls\n    - Priority management\n\n- **Resource Optimization**\n  * Efficient resource usage:\n    - Memory management\n    - Process coordination\n    - Resource pooling\n    - Load balancing\n  * Performance features:\n    - Content deduplication\n    - Path optimization\n    - State caching\n    - Batch operations\n\n- **Development Support**\n  * Visualization tools:\n    - Cache structure graphs\n    - State visualization\n    - Performance metrics\n    - Debug information\n  * Analysis capabilities:\n    - State inspection\n    - Performance analysis\n    - Error tracking\n    - Resource monitoring\n\n### 3. Integration Capabilities\nRich integration features for system interoperability:\n\n- **External Systems**\n  * Protocol support:\n    - HTTP communication\n    - GraphQL integration\n    - Custom protocols\n    - Format handling\n  * System integration:\n    - Arweave network\n    - RocksDB engine\n    - File systems\n    - Remote nodes\n\n- **Internal Coordination**\n  * State management:\n    - Process coordination\n    - Resource handling\n    - Error recovery\n    - State synchronization\n  * Security features:\n    - Access control\n    - Data protection\n    - Request validation\n    - Error isolation\n\n- **Monitoring & Control**\n  * System monitoring:\n    - Performance metrics\n    - Resource usage\n    - Error tracking\n    - State monitoring\n  * Control mechanisms:\n    - Resource limits\n    - Access controls\n    - Operation priorities\n    - System configuration\n\n## Common Usage Patterns & Examples\n\n### 1. Basic Storage Operations\nThe storage system provides straightforward patterns for common operations:\n\n```erlang\n%% Basic Data Storage\n% Write data with automatic path generation\n{ok, Path} = hb_store:write(Store, Key, Value),\n\n% Read data using path\n{ok, Data} = hb_store:read(Store, Path),\n\n% Create links between paths\nok = hb_store:make_link(Store, ExistingPath, NewPath),\n\n%% Advanced Operations\n% Write with specific options\n{ok, Path} = hb_store:write(Store, Key, Value, #{\n    type => binary,\n    compress => true,\n    metadata => #{created_at => erlang:timestamp()}\n}),\n\n% List directory contents\n{ok, Items} = hb_store:list(Store, Path),\n\n% Check path type\n{ok, Type} = hb_store:type(Store, Path)\n```\n\n### 2. Cache Management Patterns\nThe caching system supports various usage patterns:\n\n```erlang\n%% Basic Caching\n% Write to cache with policy\n{ok, ID} = hb_cache:write(Message, #{\n    store => Store,\n    cache_control => [<<\"always\">>],\n    async => true\n}),\n\n% Read from cache with options\n{ok, Data} = hb_cache:read(ID, #{\n    store_scope => local,\n    cache_control => [<<\"only-if-cached\">>]\n}),\n\n%% Advanced Caching\n% Write with deduplication\n{ok, ID} = hb_cache:write_hashpath(Message, #{\n    store => Store,\n    hashpath => CustomPath\n}),\n\n% Read resolved computation\n{ok, Result} = hb_cache:read_resolved(Msg1, Msg2, Opts)\n```\n\n### 3. Persistent Processing\nLong-lived process management patterns:\n\n```erlang\n%% Worker Management\n% Start persistent worker\nWorkerPid = hb_persistent:start_worker(Message, #{\n    static_worker => true,\n    worker_timeout => 10000,\n    error_strategy => throw\n}),\n\n% Handle execution with coordination\ncase hb_persistent:find_or_register(Msg1, Msg2, Opts) of\n    {leader, Group} -> \n        % Handle as leader\n        Result = handle_execution(Msg1, Msg2),\n        hb_persistent:unregister_notify(Group, Msg2, Result, Opts);\n    {wait, Leader} ->\n        % Wait for result\n        {ok, Result} = hb_persistent:await(Leader, Msg1, Msg2, Opts)\nend,\n\n%% Process Monitoring\n% Start monitor\nMonitorPid = hb_persistent:start_monitor(Group),\n\n% Stop monitor\nhb_persistent:stop_monitor(MonitorPid)\n```\n\n## Integration Points & System Interaction\n\n### 1. External System Integration\nThe system provides comprehensive integration with external systems:\n\n- **File System Integration**\n  * Direct file operations:\n    - Path-based access\n    - Directory management\n    - Link handling\n    - Permission control\n  * Performance optimization:\n    - Buffered operations\n    - Batch processing\n    - Async I/O\n    - Resource pooling\n\n- **RocksDB Integration**\n  * Database operations:\n    - Key-value storage\n    - Range queries\n    - Batch operations\n    - Transaction support\n  * Advanced features:\n    - Custom comparators\n    - Merge operators\n    - Column families\n    - Backup/restore\n\n- **Network Integration**\n  * Arweave connectivity:\n    - Transaction management\n    - Data permanence\n    - Network optimization\n    - State verification\n  * Remote node communication:\n    - Protocol handling\n    - State synchronization\n    - Error recovery\n    - Load balancing\n\n### 2. Internal System Integration\nDeep integration with HyperBEAM's internal systems:\n\n- **Message Processing**\n  * Message handling:\n    - Format conversion\n    - State tracking\n    - Path resolution\n    - Cache coordination\n  * Process management:\n    - Worker coordination\n    - State persistence\n    - Error handling\n    - Resource cleanup\n\n- **Resource Management**\n  * Resource control:\n    - Memory management\n    - Process limits\n    - Connection pooling\n    - Load distribution\n  * Error handling:\n    - Recovery procedures\n    - State restoration\n    - Error propagation\n    - Cleanup operations\n\n### 3. Development Tool Integration\nComprehensive tooling support:\n\n- **Visualization Tools**\n  * Graph generation:\n    - Structure visualization\n    - State inspection\n    - Performance analysis\n    - Debug support\n  * Interactive tools:\n    - Live monitoring\n    - State exploration\n    - Performance tuning\n    - Error analysis\n\n- **Debug Support**\n  * Debugging features:\n    - State inspection\n    - Error tracking\n    - Performance profiling\n    - Resource monitoring\n  * Analysis tools:\n    - Graph analysis\n    - Path validation\n    - State verification\n    - Load testing\n\n## Best Practices & Guidelines\n\n### 1. Storage System Usage\nBest practices for storage operations:\n\n- **Backend Selection**\n  * Choose based on:\n    - Performance requirements\n    - Reliability needs\n    - Distribution needs\n    - Resource constraints\n  * Consider:\n    - Data volume\n    - Access patterns\n    - Consistency needs\n    - Recovery requirements\n\n- **Error Management**\n  * Handle errors by:\n    - Validating operations\n    - Implementing recovery\n    - Managing state\n    - Cleaning resources\n  * Ensure:\n    - Data consistency\n    - State recovery\n    - Resource cleanup\n    - Error logging\n\n### 2. Cache System Usage\nGuidelines for effective caching:\n\n- **Policy Management**\n  * Configure policies:\n    - Set appropriate directives\n    - Define timeouts\n    - Manage resources\n    - Control invalidation\n  * Optimize for:\n    - Performance needs\n    - Resource usage\n    - Data freshness\n    - System load\n\n- **Resource Optimization**\n  * Manage resources:\n    - Monitor usage\n    - Set limits\n    - Handle cleanup\n    - Coordinate access\n  * Optimize for:\n    - Memory usage\n    - Process count\n    - Network load\n    - Disk usage\n\n### 3. Integration Guidelines\nBest practices for system integration:\n\n- **Protocol Compliance**\n  * Follow standards:\n    - Use correct formats\n    - Handle versions\n    - Validate data\n    - Manage errors\n  * Ensure:\n    - Compatibility\n    - Interoperability\n    - Maintainability\n    - Extensibility\n\n- **Security Considerations**\n  * Implement security:\n    - Validate input\n    - Control access\n    - Protect data\n    - Handle errors\n  * Maintain:\n    - Data integrity\n    - Access control\n    - Error isolation\n    - Audit trails\n"},"core/system_core/modules/hb_app.md":{"content":"# Module: hb_app\n\n## Basic Information\n- **Source File:** hb_app.erl\n- **Module Type:** Core System\n- **Purpose:** Main HyperBEAM application entry point\n\n## Purpose\nServes as the primary application module for HyperBEAM, implementing the OTP application behavior. This module orchestrates the system startup sequence, ensuring all core components are initialized in the correct order.\n\n## Interface\n\n### Core Operations\n- `start/2` - Start the HyperBEAM application\n- `stop/1` - Stop the HyperBEAM application\n\n## Dependencies\n\n### Direct Dependencies\n- hb: Core initialization\n- hb_sup: Root supervisor\n- dev_scheduler_registry: Scheduler management\n- ar_timestamp: Timestamp service\n- hb_http_server: HTTP server interface\n\n### Inverse Dependencies\n- Used by Erlang application controller\n- Core system startup coordinator\n- Primary system lifecycle manager\n\n## Implementation Details\n\n### Key Concepts\n\n1. **Application Startup Sequence**\n   ```erlang\n   start(_StartType, _StartArgs) ->\n       % Initialize core HyperBEAM functionality\n       hb:init(),\n       \n       % Start root supervisor\n       hb_sup:start_link(),\n       \n       % Initialize scheduler registry\n       ok = dev_scheduler_registry:start(),\n       \n       % Start timestamp service\n       _TimestampServer = ar_timestamp:start(),\n       \n       % Start HTTP server\n       {ok, _} = hb_http_server:start().\n   ```\n   The startup sequence is carefully ordered to ensure dependencies are available when needed:\n   1. Core initialization first\n   2. Supervision tree establishment\n   3. Scheduler system startup\n   4. Support services initialization\n   5. Network interface activation\n\n2. **Application Shutdown**\n   ```erlang\n   stop(_State) ->\n       ok.\n   ```\n   Clean shutdown is handled by the OTP application controller, which ensures orderly termination of the supervision tree.\n\n### State Management\n\n1. **System State**\n   - Application lifecycle state\n   - Component initialization status\n   - Service availability tracking\n   - Resource allocation state\n\n2. **Component State**\n   - Supervisor tree state\n   - Service process states\n   - Resource states\n   - Network interface state\n\n3. **Startup State**\n   - Initialization sequence state\n   - Dependency resolution state\n   - Service startup state\n   - Error handling state\n\n### Error Handling\n\n1. **Startup Errors**\n   - Initialization failures\n   - Supervisor startup errors\n   - Service startup failures\n   - Resource allocation errors\n\n2. **Shutdown Errors**\n   - Resource cleanup failures\n   - Process termination errors\n   - State cleanup issues\n   - Network shutdown problems\n\n## Integration Points\n\n1. **OTP Integration**\n   - Application behavior\n   - Supervision principles\n   - Process management\n   - Error handling\n\n2. **System Services**\n   - Scheduler system\n   - Timestamp service\n   - HTTP interface\n   - Resource management\n\n3. **Core Systems**\n   - Initialization system\n   - Supervision system\n   - Network system\n   - Resource system\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Startup Performance**\n   - Sequential initialization\n   - Resource allocation\n   - Service startup\n   - State establishment\n\n2. **System Impact**\n   - Memory footprint\n   - Process overhead\n   - Resource usage\n   - Network impact\n\n### Security Implications\n\n1. **System Security**\n   - Component isolation\n   - Resource protection\n   - Service security\n   - Network security\n\n2. **Startup Security**\n   - Initialization safety\n   - Resource protection\n   - Service isolation\n   - Error containment\n\n### Best Practices\n\n1. **Application Design**\n   - Follow OTP principles\n   - Proper initialization\n   - Clean shutdown\n   - Error handling\n\n2. **Integration**\n   - Service coordination\n   - Resource management\n   - Error handling\n   - State tracking\n\n3. **System Management**\n   - Proper startup\n   - Clean shutdown\n   - Resource cleanup\n   - Error recovery\n\n### Example Usage\n\n```erlang\n% Application startup (via application controller)\napplication:start(hyperbeam).\n\n% This triggers the following sequence:\n1. hb:init()              % Core initialization\n2. hb_sup:start_link()    % Supervisor tree\n3. dev_scheduler_registry:start() % Scheduler system\n4. ar_timestamp:start()   % Timestamp service\n5. hb_http_server:start() % Network interface\n\n% Application shutdown\napplication:stop(hyperbeam).\n\n% This triggers:\n1. OTP shutdown sequence\n2. Supervisor tree termination\n3. Resource cleanup\n4. Process termination\n```\n\n## Startup Flow Visualization\n\n```mermaid\nsequenceDiagram\n    participant AC as App Controller\n    participant App as hb_app\n    participant Core as hb:init\n    participant Sup as hb_sup\n    participant Sched as Scheduler\n    participant Time as Timestamp\n    participant HTTP as HTTP Server\n\n    AC->>App: start(Type, Args)\n    App->>Core: init()\n    Note over Core: Initialize core systems\n    \n    App->>Sup: start_link()\n    Note over Sup: Start supervision tree\n    \n    App->>Sched: start()\n    Note over Sched: Initialize scheduler\n    \n    App->>Time: start()\n    Note over Time: Start timestamp service\n    \n    App->>HTTP: start()\n    Note over HTTP: Start HTTP interface\n    \n    App->>AC: {ok, Pid}\n```\n\n## Shutdown Flow Visualization\n\n```mermaid\nsequenceDiagram\n    participant AC as App Controller\n    participant App as hb_app\n    participant Sup as Supervisor\n    participant Procs as Processes\n\n    AC->>App: stop(State)\n    App->>Sup: stop children\n    Sup->>Procs: terminate\n    Note over Procs: Cleanup resources\n    Procs->>Sup: terminated\n    Sup->>App: stopped\n    App->>AC: ok\n"},"core/system_core/modules/hb_features.md":{"content":"# Module: hb_features\n\n## Basic Information\n- **Source File:** hb_features.erl\n- **Module Type:** Core System\n- **Purpose:** Feature flag management and build-time configuration proxy\n\n## Purpose\nActs as a bridge between the build system and runtime environment by exposing compile-time feature flags through a unified interface. This module uses Erlang's `-ifdef` macro system to conditionally enable features based on build-time configuration.\n\n## Interface\n\n### Core Operations\n- `all/0` - Get map of all feature flags and their states\n- `enabled/1` - Check if specific feature is enabled\n- `http3/0` - Check HTTP/3 support\n- `rocksdb/0` - Check RocksDB support\n- `test/0` - Check test mode\n- `genesis_wasm/0` - Check Genesis WASM support\n\n## Dependencies\n\n### Direct Dependencies\n- Erlang compiler: `-ifdef` macro system\n- Build system: Feature flag definitions\n- Module info system: Export introspection\n\n### Inverse Dependencies\n- Used by all modules requiring feature checks\n- Core system capability provider\n- Build system integration point\n\n## Implementation Details\n\n### Key Concepts\n\n1. **Feature Flag System**\n   ```erlang\n   % Feature flag definition pattern\n   -ifdef(ENABLE_FEATURE).\n   feature() -> true.\n   -else.\n   feature() -> false.\n   -endif.\n   ```\n   Each feature is defined using conditional compilation:\n   - Build system defines `ENABLE_*` macros\n   - Compile-time resolution of features\n   - Runtime access to build decisions\n\n2. **Feature Discovery**\n   ```erlang\n   all() ->\n       Features =\n           lists:filtermap(\n               fun({Name, _}) ->\n                   case lists:member(Name, [all, enabled, module_info]) of\n                       true -> false;\n                       false -> {true, Name}\n                   end\n               end,\n               ?MODULE:module_info(exports)\n           ),\n       maps:from_list(\n           lists:map(\n               fun(Name) ->\n                   {Name, ?MODULE:Name()}\n               end,\n               Features\n           )\n       ).\n   ```\n   Dynamic feature discovery through module introspection:\n   - Examines exported functions\n   - Filters utility functions\n   - Maps feature names to states\n\n3. **Feature Checking**\n   ```erlang\n   enabled(Feature) ->\n       maps:get(Feature, all(), false).\n   ```\n   Safe feature checking with defaults:\n   - Unified interface\n   - Default to disabled\n   - Runtime caching\n\n### State Management\n\n1. **Build State**\n   - Compile-time flags\n   - Feature definitions\n   - Macro system\n   - Build configuration\n\n2. **Runtime State**\n   - Feature availability\n   - Capability flags\n   - System state\n   - Feature map\n\n3. **Feature State**\n   ```erlang\n   % Current feature set\n   - http3: HTTP/3 protocol support\n   - rocksdb: RocksDB storage backend\n   - test: Test mode configuration\n   - genesis_wasm: WASM execution support\n   ```\n\n### Error Handling\n\n1. **Feature Checks**\n   ```erlang\n   % Safe feature checking\n   enabled(Feature) ->\n       maps:get(Feature, all(), false).\n   ```\n   - Default to disabled\n   - Safe lookups\n   - Error prevention\n   - State protection\n\n2. **Build Integration**\n   - Macro validation\n   - Feature consistency\n   - Build errors\n   - State verification\n\n## Integration Points\n\n1. **Build System**\n   - Feature definitions\n   - Macro system\n   - Compilation flags\n   - Build configuration\n\n2. **Runtime System**\n   - Feature checks\n   - Capability queries\n   - State access\n   - System configuration\n\n3. **Module System**\n   - Export introspection\n   - Function discovery\n   - State mapping\n   - Feature access\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Build Impact**\n   - Compile-time resolution\n   - Dead code elimination\n   - Feature optimization\n   - Size reduction\n\n2. **Runtime Impact**\n   - Fast feature checks\n   - State caching\n   - Memory efficiency\n   - Access patterns\n\n### Security Implications\n\n1. **Feature Control**\n   - Build-time locking\n   - Runtime protection\n   - State isolation\n   - Access control\n\n2. **System Protection**\n   - Feature isolation\n   - State protection\n   - Error prevention\n   - Access control\n\n### Best Practices\n\n1. **Feature Management**\n   - Clear definitions\n   - Build integration\n   - State tracking\n   - Error handling\n\n2. **Integration**\n   - Build system\n   - Runtime system\n   - Error handling\n   - State management\n\n3. **Usage Patterns**\n   - Feature checks\n   - State access\n   - Error handling\n   - Capability queries\n\n### Example Usage\n\n```erlang\n% Check individual features\nIsHTTP3 = hb_features:http3(),\nIsRocksDB = hb_features:rocksdb(),\nIsTest = hb_features:test(),\n\n% Check specific feature\ncase hb_features:enabled(http3) of\n    true -> \n        % Use HTTP/3\n        setup_http3();\n    false ->\n        % Fallback to HTTP/2\n        setup_http2()\nend,\n\n% Get all features\nFeatures = hb_features:all(),\nio:format(\"Available features: ~p~n\", [maps:keys(Features)]),\n\n% Conditional behavior\ncase hb_features:enabled(genesis_wasm) of\n    true ->\n        execute_wasm_code(Code);\n    false ->\n        {error, wasm_not_supported}\nend\n```\n\n## Feature Resolution Flow\n\n```mermaid\ngraph TD\n    A[Build System] -->|Define Macros| B[Compiler]\n    B -->|Conditional Compilation| C[Feature Module]\n    C -->|Export Functions| D[Runtime]\n    D -->|Query Features| E[Application]\n    \n    subgraph \"Build Time\"\n        A\n        B\n    end\n    \n    subgraph \"Runtime\"\n        C\n        D\n        E\n    end\n```\n\n## Feature Check Flow\n\n```mermaid\nsequenceDiagram\n    participant App as Application\n    participant Feat as hb_features\n    participant Cache as Feature Cache\n    participant Build as Build Config\n\n    App->>Feat: enabled(feature)\n    Feat->>Cache: check_cache()\n    \n    alt Cache Miss\n        Feat->>Build: check_build_flag()\n        Build->>Feat: flag_state\n        Feat->>Cache: update_cache()\n    end\n    \n    Feat->>App: feature_state\n"},"core/system_core/modules/hb_name.md":{"content":"# Module: hb_name\n\n## Basic Information\n- **Source File:** hb_name.erl\n- **Module Type:** Core System\n- **Purpose:** Extended process registration system\n\n## Purpose\nProvides an abstraction layer over Erlang's process registration system that allows registering processes with any term as a name, not just atoms. This enables more flexible process identification while maintaining atomic registration guarantees. The module is particularly important for HyperBEAM's distributed architecture where processes may need to be identified by hashpaths or versioned IDs.\n\n## Interface\n\n### Core Operations\n- `start/0` - Initialize the name registry\n- `register/1` - Register current process with a name\n- `register/2` - Register specific process with a name\n- `unregister/1` - Remove name registration\n- `lookup/1` - Find process by name\n- `all/0` - List all registered names\n\n## Dependencies\n\n### Direct Dependencies\n- ets: Storage for non-atom registrations\n- erlang: Native process registration\n- timer: Test utilities\n- eunit: Testing framework\n\n### Inverse Dependencies\n- Used by all modules requiring process registration\n- Core system naming provider\n- Process discovery service\n\n## Implementation Details\n\n### Key Concepts\n\n1. **ETS-Based Registry**\n   ```erlang\n   % Initialize ETS table with optimized settings\n   start_ets() ->\n       ets:new(?NAME_TABLE, [\n           named_table,\n           public,\n           {keypos, 1},\n           {write_concurrency, true}, % Safe as key-writes are atomic\n           {read_concurrency, true}\n       ]),\n       ok.\n   ```\n   The registry uses ETS for:\n   - Atomic operations\n   - Concurrent access\n   - Fast lookups\n   - Process monitoring\n\n2. **Hybrid Registration**\n   ```erlang\n   % Registration handling based on name type\n   register(Name, Pid) when is_atom(Name) ->\n       try erlang:register(Name, Pid) of\n           true -> ok\n       catch\n           error:badarg -> error % Name already registered\n       end;\n   register(Name, Pid) ->\n       start(),\n       case ets:insert_new(?NAME_TABLE, {Name, Pid}) of\n           true -> ok;\n           false -> error\n       end.\n   ```\n   Seamless integration of:\n   - Erlang's native registration\n   - ETS-based registration\n   - Atomic operations\n   - Error handling\n\n3. **Process Monitoring**\n   ```erlang\n   % Dead process cleanup during lookup\n   ets_lookup(Name) ->\n       case ets:lookup(?NAME_TABLE, Name) of\n           [{Name, Pid}] -> \n               case is_process_alive(Pid) of\n                   true -> Pid;\n                   false -> \n                       ets:delete(?NAME_TABLE, Name),\n                       undefined\n               end;\n           [] -> undefined\n       end.\n   ```\n   Automatic cleanup of:\n   - Dead processes\n   - Stale registrations\n   - Invalid entries\n   - Resource management\n\n### State Management\n\n1. **Registry State**\n   ```erlang\n   % Registry initialization with safety checks\n   start() ->\n       try ets:info(?NAME_TABLE) of\n           undefined -> start_ets();\n           _ -> ok\n       catch\n           error:badarg -> start_ets()\n       end.\n   ```\n   Careful management of:\n   - Table initialization\n   - State consistency\n   - Error recovery\n   - Resource cleanup\n\n2. **Process State**\n   ```erlang\n   % Process state verification\n   case is_process_alive(Pid) of\n       true -> Pid;\n       false -> \n           ets:delete(?NAME_TABLE, Name),\n           undefined\n   end\n   ```\n   Monitoring of:\n   - Process lifecycle\n   - Registration validity\n   - Resource cleanup\n   - State consistency\n\n### Error Handling\n\n1. **Registration Errors**\n   ```erlang\n   % Safe registration with error handling\n   register(Name, Pid) when is_atom(Name) ->\n       try erlang:register(Name, Pid) of\n           true -> ok\n       catch\n           error:badarg -> error\n       end\n   ```\n   Comprehensive handling of:\n   - Duplicate registrations\n   - Invalid names\n   - Dead processes\n   - Resource errors\n\n2. **Cleanup Operations**\n   ```erlang\n   % Safe unregistration with cleanup\n   unregister(Name) when is_atom(Name) ->\n       catch erlang:unregister(Name),\n       ets:delete(?NAME_TABLE, Name),  % Cleanup if atom was in ETS\n       ok\n   ```\n   Safe management of:\n   - Process termination\n   - Registration cleanup\n   - Resource recovery\n   - State consistency\n\n## Integration Points\n\n1. **Process System**\n   - Process registration\n   - Name management\n   - State tracking\n   - Resource coordination\n\n2. **Storage System**\n   - ETS table management\n   - State persistence\n   - Atomic operations\n   - Concurrent access\n\n3. **Runtime System**\n   - Process monitoring\n   - State management\n   - Error handling\n   - Resource cleanup\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Registration Performance**\n   ```erlang\n   % Optimized table configuration\n   ets:new(?NAME_TABLE, [\n       named_table,\n       public,\n       {keypos, 1},\n       {write_concurrency, true},\n       {read_concurrency, true}\n   ])\n   ```\n   Performance optimizations:\n   - Concurrent access\n   - Fast lookups\n   - Atomic operations\n   - Resource efficiency\n\n2. **Cleanup Impact**\n   ```erlang\n   % Lazy cleanup during lookup\n   case is_process_alive(Pid) of\n       true -> Pid;\n       false -> \n           ets:delete(?NAME_TABLE, Name),\n           undefined\n   end\n   ```\n   Resource management:\n   - Lazy cleanup\n   - On-demand verification\n   - Efficient deletion\n   - State consistency\n\n### Security Implications\n\n1. **Registration Protection**\n   - Atomic operations\n   - Process validation\n   - Name uniqueness\n   - Resource isolation\n\n2. **State Protection**\n   - Consistent state\n   - Safe cleanup\n   - Error handling\n   - Resource management\n\n### Best Practices\n\n1. **Registration Usage**\n   - Atomic operations\n   - Error handling\n   - State verification\n   - Resource cleanup\n\n2. **Integration**\n   - Process monitoring\n   - State management\n   - Error handling\n   - Resource coordination\n\n3. **System Design**\n   - Atomic guarantees\n   - Concurrent access\n   - Safe cleanup\n   - Resource efficiency\n\n### Example Usage\n\n```erlang\n% Basic registration\nok = hb_name:register(my_process),\nself() = hb_name:lookup(my_process),\n\n% Custom name registration\nProcessName = {process, \"1.0\", generate_id()},\nok = hb_name:register(ProcessName),\nself() = hb_name:lookup(ProcessName),\n\n% Registration with specific PID\nWorker = spawn(fun() -> worker_loop() end),\nok = hb_name:register(worker_process, Worker),\nWorker = hb_name:lookup(worker_process),\n\n% List all registrations\nRegistered = hb_name:all(),\nio:format(\"Active processes: ~p~n\", [Registered]),\n\n% Cleanup\nok = hb_name:unregister(ProcessName)\n```\n\n## Registration Flow\n\n```mermaid\ngraph TD\n    A[Registration Request] -->|Name Type Check| B{Is Atom?}\n    B -->|Yes| C[Erlang Register]\n    B -->|No| D[ETS Register]\n    \n    C -->|Success| E[Registered]\n    C -->|Error| F[Failed]\n    \n    D -->|Insert New| E\n    D -->|Exists| F\n    \n    subgraph \"State Management\"\n        G[Process Monitor]\n        H[State Cleanup]\n    end\n    \n    E --> G\n    G -->|Dead Process| H\n```\n\n## Lookup Flow\n\n```mermaid\nsequenceDiagram\n    participant App as Application\n    participant Name as hb_name\n    participant ETS as ETS Table\n    participant Erlang as Erlang Registry\n\n    App->>Name: lookup(Name)\n    \n    alt Is Atom\n        Name->>Erlang: whereis(Name)\n        Erlang-->>Name: PID/undefined\n        \n        alt undefined\n            Name->>ETS: lookup(Name)\n            ETS-->>Name: PID/undefined\n        end\n    else\n        Name->>ETS: lookup(Name)\n        ETS-->>Name: PID/undefined\n    end\n    \n    alt Found PID\n        Name->>Name: verify_alive(PID)\n    end\n    \n    Name-->>App: PID/undefined\n"},"core/system_core/modules/hb_opts.md":{"content":"# Module: hb_opts\n\n## Basic Information\n- **Source File:** hb_opts.erl\n- **Module Type:** Core System\n- **Purpose:** Configuration management system for HyperBEAM\n\n## Purpose\nProvides a unified interface for managing both global and local configuration options throughout HyperBEAM. The module implements a sophisticated configuration system that handles environment variables, default values, and local overrides while ensuring deterministic behavior for critical operations.\n\n## Interface\n\n### Core Operations\n- `get/1` - Get option with default undefined\n- `get/2` - Get option with custom default\n- `get/3` - Get option with custom default and local overrides\n- `load/1` - Load configuration from flat file\n- `default_message/0` - Get default configuration map\n- `mimic_default_types/2` - Convert map values to match default types\n\n## Dependencies\n\n### Direct Dependencies\n- dev_codec_flat: Configuration file parsing\n- hb_util: Utility functions\n- hb_features: Feature flags\n- os: Environment variables\n\n### Inverse Dependencies\n- Used by all HyperBEAM modules for configuration\n- Core system configuration provider\n- Primary determinism enforcer\n\n## Implementation Details\n\n### Key Concepts\n\n1. **Configuration Hierarchy**\n   ```erlang\n   % Configuration lookup order\n   get(Key, Default, Opts = #{ prefer := local }) ->\n       case ?MODULE:get(Key, hb_opts_not_found, Opts#{ only => local }) of\n           hb_opts_not_found ->\n               ?MODULE:get(Key, Default, Opts#{ only => global });\n           Value -> Value\n       end\n   ```\n   The system implements a sophisticated lookup hierarchy:\n   1. Local options (if preferred)\n   2. Global options\n   3. Environment variables\n   4. Default values\n\n2. **Deterministic Behavior**\n   ```erlang\n   % Options must never change deterministic behavior\n   % Example from documentation:\n   %%% Options set in an `Opts' map must _never_ change the behavior of a function\n   %%% that should otherwise be deterministic. Doing so may lead to loss of funds\n   %%% by the HyperBEAM node operator, as the results of their executions will be\n   %%% different than those of other node operators.\n   ```\n   Critical focus on maintaining deterministic execution across nodes.\n\n3. **Environment Integration**\n   ```erlang\n   -define(ENV_KEYS,\n       #{\n           priv_key_location => {\"HB_KEY\", \"hyperbeam-key.json\"},\n           hb_config_location => {\"HB_CONFIG\", \"config.flat\"},\n           port => {\"HB_PORT\", fun erlang:list_to_integer/1, \"8734\"},\n           mode => {\"HB_MODE\", fun list_to_existing_atom/1},\n           debug_print => {\"HB_PRINT\", fun(...) -> ... end}\n       }\n   ).\n   ```\n   Sophisticated environment variable handling with type conversion.\n\n### State Management\n\n1. **Configuration State**\n   ```erlang\n   % Default configuration map\n   default_message() ->\n       #{\n           % Core settings\n           initialized => true,\n           http_client => gun,\n           scheduling_mode => local_confirmation,\n           compute_mode => lazy,\n           \n           % Network settings\n           host => <<\"localhost\">>,\n           gateway => <<\"https://arweave.net\">>,\n           port => 8734,\n           \n           % Security settings\n           priv_key_location => <<\"hyperbeam-key.json\">>,\n           trusted_device_signers => [],\n           \n           % Performance settings\n           http_connect_timeout => 5000,\n           http_keepalive => 120000,\n           scheduler_location_ttl => (60 * 60 * 24 * 7) * 1000\n       }\n   ```\n   Comprehensive default configuration covering all system aspects.\n\n2. **Type Management**\n   ```erlang\n   % Type conversion based on defaults\n   mimic_default_types(Map, Mode) ->\n       Default = default_message(),\n       maps:from_list(lists:map(\n           fun({Key, Value}) ->\n               NewKey = hb_util:key_to_atom(Key, Mode),\n               NewValue = \n                   case maps:get(NewKey, Default, not_found) of\n                       not_found -> Value;\n                       DefaultValue when is_atom(DefaultValue) ->\n                           hb_util:atom(Value);\n                       DefaultValue when is_integer(DefaultValue) ->\n                           hb_util:int(Value);\n                       DefaultValue when is_float(DefaultValue) ->\n                           hb_util:float(Value);\n                       DefaultValue when is_binary(DefaultValue) ->\n                           Value;\n                       _ -> Value\n                   end,\n               {NewKey, NewValue}\n           end,\n           maps:to_list(Map)\n       )).\n   ```\n   Automatic type conversion based on default values.\n\n### Error Handling\n\n1. **Configuration Errors**\n   ```erlang\n   load(Path) ->\n       case file:read_file(Path) of\n           {ok, Bin} ->\n               try dev_codec_flat:deserialize(Bin) of\n                   {ok, Map} -> {ok, mimic_default_types(Map, new_atoms)}\n               catch\n                   error:B -> {error, B}\n               end;\n           _ -> {error, not_found}\n       end.\n   ```\n   Comprehensive error handling for configuration loading.\n\n2. **Type Conversion Errors**\n   ```erlang\n   % Environment variable parsing with error handling\n   global_get(Key, Default) ->\n       case maps:get(Key, ?ENV_KEYS, Default) of\n           {EnvKey, ValParser} when is_function(ValParser) ->\n               case cached_os_env(EnvKey, not_found) of\n                   not_found -> config_lookup(Key, Default);\n                   Value -> ValParser(Value)\n               end;\n           % ... other cases\n       end.\n   ```\n   Safe type conversion with fallbacks.\n\n## Integration Points\n\n1. **Environment System**\n   - Environment variables\n   - System configuration\n   - Default values\n   - Type conversion\n\n2. **Configuration System**\n   - File-based configuration\n   - Runtime overrides\n   - Type management\n   - Error handling\n\n3. **Application System**\n   - Global settings\n   - Local overrides\n   - Feature flags\n   - Debug options\n\n## Analysis Insights\n\n### Performance Considerations\n\n1. **Configuration Caching**\n   ```erlang\n   % Environment variable caching\n   cached_os_env(Key, DefaultValue) ->\n       case erlang:get({os_env, Key}) of\n           undefined ->\n               case os:getenv(Key) of\n                   false -> DefaultValue;\n                   Value ->\n                       erlang:put({os_env, Key}, Value),\n                       Value\n               end;\n           Value -> Value\n       end.\n   ```\n   Efficient caching of environment variables.\n\n2. **Type Conversion**\n   - Lazy conversion\n   - Cached results\n   - Default fallbacks\n   - Error recovery\n\n### Security Implications\n\n1. **Configuration Security**\n   ```erlang\n   % Security-critical settings\n   #{\n       trusted_device_signers => [],\n       load_remote_devices => false,\n       debug_show_priv => false,\n       trusted => #{}\n   }\n   ```\n   Careful management of security settings.\n\n2. **Determinism Protection**\n   - Option validation\n   - Behavior constraints\n   - Error handling\n   - State protection\n\n### Best Practices\n\n1. **Configuration Management**\n   - Clear hierarchy\n   - Type safety\n   - Error handling\n   - Default values\n\n2. **Integration**\n   - Environment awareness\n   - System coordination\n   - Error handling\n   - State management\n\n3. **Security**\n   - Safe defaults\n   - Validation\n   - Error handling\n   - State protection\n\n### Example Usage\n\n```erlang\n% Basic option retrieval\nValue = hb_opts:get(key),\nValue = hb_opts:get(key, default_value),\n\n% Local overrides\nValue = hb_opts:get(key, default_value, #{\n    key => override_value,\n    prefer => local\n}),\n\n% Load configuration file\n{ok, Config} = hb_opts:load(\"config.flat\"),\n\n% Configuration with type conversion\nConfig = #{\n    \"port\" => \"1234\",\n    \"host\" => \"localhost\",\n    \"debug\" => \"true\"\n},\nTypedConfig = hb_opts:mimic_default_types(Config, new_atoms)\n```\n\n## Configuration Flow\n\n```mermaid\ngraph TD\n    A[Local Options] -->|Preferred| D[Final Value]\n    B[Global Options] -->|Fallback| D\n    C[Environment] -->|Override| B\n    E[Defaults] -->|Fallback| D\n    \n    subgraph \"Type System\"\n        F[Default Types]\n        G[Type Conversion]\n        H[Validation]\n    end\n    \n    D --> G\n    F --> G\n    G --> H\n```\n\n## Option Resolution Flow\n\n```mermaid\nsequenceDiagram\n    participant App as Application\n    participant Opts as hb_opts\n    participant Env as Environment\n    participant File as Config File\n    participant Cache as Process Dictionary\n\n    App->>Opts: get(key, default, local_opts)\n    \n    alt Local Preferred\n        Opts->>Opts: Check local_opts\n        Opts->>Opts: Check global\n        Opts->>Env: Check environment\n        Opts->>File: Check config file\n    else Global Preferred\n        Opts->>Opts: Check global\n        Opts->>Env: Check environment\n        Opts->>File: Check config file\n        Opts->>Opts: Check local_opts\n    end\n    \n    Opts->>Cache: Cache result\n    Opts->>App: Return value\n"}}